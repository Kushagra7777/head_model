{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook makes setolabo samples as test samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "df_GRE = pd.read_excel('E:/MedBank/head_model/NGS/data_shared_by_Takeshi-san/PRJNA946800.xlsx')\n",
    "df_seto = pd.read_csv('E:/MedBank/head_model/NGS/data_shared_by_Takeshi-san/expression_count_test_20240807.csv')\n",
    "\n",
    "# Remove duplicates from df_GRE based on 'miRNA'\n",
    "df_GRE = df_GRE.drop_duplicates(subset=['miRNA'], keep='first')\n",
    "\n",
    "# Create labels for df_GRE (case = 0, control = 1)\n",
    "columns = df_GRE.columns.tolist()\n",
    "labels_GRE = []\n",
    "for item in columns:\n",
    "    if item.startswith('case'):\n",
    "        labels_GRE.append(0)\n",
    "    elif item.startswith('control'):\n",
    "        labels_GRE.append(1)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "# Set labels for df_seto as 0 (since all are cancerous)\n",
    "labels_seto = [0 for _ in range(5)]\n",
    "\n",
    "# Filter both datasets based on common 'miRNA' / 'gene_id'\n",
    "features = df_GRE['miRNA'].tolist()\n",
    "df_seto = df_seto[df_seto['gene_id'].isin(features)]\n",
    "features = df_seto['gene_id']\n",
    "df_GRE = df_GRE[df_GRE['miRNA'].isin(features)]\n",
    "\n",
    "# Sort both DataFrames by 'miRNA' / 'gene_id' to align them\n",
    "df_GRE = df_GRE.sort_values(by='miRNA')\n",
    "df_seto = df_seto.sort_values(by='gene_id')\n",
    "\n",
    "# Transpose the DataFrames and reset their index\n",
    "df_GRE = df_GRE.T\n",
    "df_seto = df_seto.T\n",
    "df_GRE.reset_index(drop=True, inplace=True)\n",
    "df_seto.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Update the column names after transposing\n",
    "df_seto.columns = df_seto.iloc[0].tolist()\n",
    "df_seto = df_seto[1:]\n",
    "df_GRE.columns = df_GRE.iloc[0].tolist()\n",
    "df_GRE = df_GRE[1:]\n",
    "\n",
    "# Assign labels to the GRE and seto datasets\n",
    "df_GRE['labels'] = labels_GRE\n",
    "df_seto['labels'] = labels_seto\n",
    "\n",
    "# No train-test split, df_GRE is the full training set and df_seto is the testing set\n",
    "df_train = df_GRE.iloc[:, :-1]  # Features of the full training set\n",
    "df_test = df_seto.iloc[:, :-1]  # Features of the full testing set\n",
    "\n",
    "# Create labels_train and labels_test\n",
    "labels_train = df_GRE['labels'].tolist()\n",
    "labels_test = df_seto['labels'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define NGS version as a variable\n",
    "folder_path = \"E:/MedBank/head_model/NGS/data_shared_by_Takeshi-san/model_ready_folders/setolabo_samples_as_test/PRJNA946800\"  # You can change this value as needed\n",
    "\n",
    "# Paths for train and test feature vectors\n",
    "file_path = f\"{folder_path}/train/feature_vectors.csv\"\n",
    "df_train.to_csv(file_path, index=False, header=False)\n",
    "\n",
    "file_path = f\"{folder_path}/test/feature_vectors.csv\"\n",
    "df_test.to_csv(file_path, index=False, header=False)\n",
    "\n",
    "##--------------------------------------------------------\n",
    "\n",
    "# Paths for train and test labels\n",
    "file_path = f\"{folder_path}/train/labels.txt\"\n",
    "with open(file_path, 'w') as file:\n",
    "    for label in labels_train:\n",
    "        file.write(f\"{label}\\n\")\n",
    "\n",
    "file_path = f\"{folder_path}/test/labels.txt\"\n",
    "with open(file_path, 'w') as file:\n",
    "    for label in labels_test:\n",
    "        file.write(f\"{label}\\n\")\n",
    "\n",
    "##--------------------------------------------------------\n",
    "\n",
    "# Path for feature names\n",
    "file_path = f\"{folder_path}/feature_names.txt\"\n",
    "with open(file_path, 'w') as file:\n",
    "    for label in features:\n",
    "        file.write(f\"{label}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "text = 'case/sample_analysis/ERR372264/ERR372264_sort.bam'\n",
    "if text.startswith('case'):\n",
    "    print(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
